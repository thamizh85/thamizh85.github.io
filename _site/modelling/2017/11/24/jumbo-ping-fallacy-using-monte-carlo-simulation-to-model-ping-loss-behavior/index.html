
<!doctype html>














<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="google9355da1d9e940142.html" />













  
  
  <link href="/assets/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/assets/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/assets/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="network,python,numpy,probability,scripting," />





  <link rel="alternate" href="/atom.xml" title="Ephemeral Electrons" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/assets/favicon.ico?v=5.1.1" />
















<meta name="description" content="Background Recently we had a cabling issue in our core infrastructure which caused around 3 to 12% packet loss across few IP streams. One of my colleagues made an interesting observation that when he tried to ping with large packet size (5000 bytes) the packet loss rose up to 40%. In his opinion, that meant some applications were experiencing up to 40% packet loss. I seldom do large packet ping tests unless I am troubleshooting MTU issues, so to me this observation was interesting. At the outset, it may look like an aggravated problem. But you know that your network path MTU doesn’t support jumbo frames end-to-end. If so why is there a difference in packet loss rate when you ping with large datagams? Once you reason that the ping test results only represent ICMP datagram loss and not ethernet frame loss, you will realize that both tests results represent the same network performane but in different metrics. Interpreting them as two separate test cases is fallacious. Let us explore why. Normal ping vs Large ping In windows a normal ping packet size is 32 bytes and in most environments, the default MTU is 1500 bytes. So a single frame is sufficient to transmit a ping packet. Things get weirder when we ping with large packets. In windows, you can specify the ping packet size using -l option. Note that this size doesn’t include the packet header (20 bytes for IP header + 8 bytes for ICMP header). Which means with a 1500 MTU size, we can send only up to 1472 bytes in a single frame. Any length above this must be fragmented. We can test this easily. Below is the result when pinging with 1472 as the ping size (ping 8.8.8.8 -n 2 -l 1472) Capturing on &apos;Ethernet 2&apos; 1 0.000000 10.1.1.1 → 8.8.8.8 ICMP 1514 Echo (ping) request id=0x0001, seq=8/2048, ttl=128 2 0.015698 8.8.8.8 → 10.1.1.1 ICMP 106 Echo (ping) reply id=0x0001, seq=8/2048, ttl=45 2 packets captured When we ping with just one more byte, you can see that 2 packets are sent in place of 1 ((ping 8.8.8.8 -n 2 -l 1473) Capturing on &apos;Ethernet 2&apos; 1 0.000000 10.1.1.1 → 8.8.8.8 IPv4 1514 Fragmented IP protocol (proto=ICMP 1, off=0, ID=4fab) 2 0.000016 10.1.1.1 → 8.8.8.8 ICMP 35 Echo (ping) request id=0x0001, seq=10/2560, ttl=128 2 packets captured So when we ping with 5000 bytes, 4 packets are sent. And ICMP protocol considers a datagram to be lost even when one of them fails. So the probability of the ICMP datagram loss is higher than the probability of single frame loss. But is this what is happening in the ping test result? We can calculate the probability of datagram loss using probability theory but let us defer to it later on and do a numerical simulation first using Monte Carlo simulation. Monte Carlo Simulation Monte carlo simulation is a rather fancy title for a simple simulation using random event generator, but it is quite handy and widely used. Usually Monte Carlo simulation is useful for simulating events that are truly random in nature. In a chaotic backbone network, that handles traffic stream of different kinds, we can assume the frame loss to happen approximately in a random fashion. Let us write a short program to simulate random packet loss. import random import numpy as np sampleCount = 100000 # total events in our simulation p = 0.03 # ethernet frame loss probability grpSize = 4 # packet count per datagram, 5000 bytes = 4 packets grpEventCount = int(sampleCount/grpSize) # datagram count # generate random packets with p% packet loss events = np.random.choice([0,1], size=sampleCount, p=[p,1-p]) # group discrete packets into a datagram grpEvents = events.reshape(grpEventCount,grpSize) # function to determine datagram loss def checkFailure(grpEvent): return (np.count_nonzero(grpEvent) &amp;lt; grpSize) # Return 1 if the success count is less than 3 # count the result failCount = 0 for grpEvent in grpEvents: failCount += checkFailure(grpEvent) print(&quot;The probability of a group failure is {:.2f}%&quot;.format(failCount/len(grpEvents)*100)) The probability of a group failure is 11.78% There you see! Even a 3% ethernet frame loss translates to 12% packet loss for jumbo ping test. This is same as what we observed. Now this is just a simulation with random input. But does the math agree? Using Probability Theory If p is the probability of a single frame loss, (1-p) is the probability of a successful transfer. And a datagram is successful only if all of its frames are successful. So an ICMP datagram which is 4 frame long, will have (1-p)**4 probability of succesful delivery. To calculate the failure rate, just take its inverse. 1- (1-p)**4 0.11470719000000007 As expected the simulation is slightly off from the calculated probability. But it will get closer to the real figure when we increase the simulation count. Conclusion The exactness of our calculation hinges on the assumption of random nature of packet loss. While it happened to be close to true in my case, it need not be all the time. The link may be loaded in a bursty manner and since our ping streams are evenly spaced over time, their chances of failure may not be truly random. Nevertheless, we should be wary of the difference between a datagram loss and ethernet loss while interpreting results. Consider the MTU of the network path while testing with different packet sizes. Jupyter notebook version of this post can be viewed here">
<meta name="keywords" content="network, python, numpy, probability, scripting">
<meta property="og:type" content="article">
<meta property="og:title" content="Jumbo Ping Fallacy- Using Monte-Carlo Simulation to model ping loss behavior">
<meta property="og:url" content="http://localhost:4000/modelling/2017/11/24/jumbo-ping-fallacy-using-monte-carlo-simulation-to-model-ping-loss-behavior/">
<meta property="og:site_name" content="Ephemeral Electrons">
<meta property="og:description" content="Background Recently we had a cabling issue in our core infrastructure which caused around 3 to 12% packet loss across few IP streams. One of my colleagues made an interesting observation that when he tried to ping with large packet size (5000 bytes) the packet loss rose up to 40%. In his opinion, that meant some applications were experiencing up to 40% packet loss. I seldom do large packet ping tests unless I am troubleshooting MTU issues, so to me this observation was interesting. At the outset, it may look like an aggravated problem. But you know that your network path MTU doesn’t support jumbo frames end-to-end. If so why is there a difference in packet loss rate when you ping with large datagams? Once you reason that the ping test results only represent ICMP datagram loss and not ethernet frame loss, you will realize that both tests results represent the same network performane but in different metrics. Interpreting them as two separate test cases is fallacious. Let us explore why. Normal ping vs Large ping In windows a normal ping packet size is 32 bytes and in most environments, the default MTU is 1500 bytes. So a single frame is sufficient to transmit a ping packet. Things get weirder when we ping with large packets. In windows, you can specify the ping packet size using -l option. Note that this size doesn’t include the packet header (20 bytes for IP header + 8 bytes for ICMP header). Which means with a 1500 MTU size, we can send only up to 1472 bytes in a single frame. Any length above this must be fragmented. We can test this easily. Below is the result when pinging with 1472 as the ping size (ping 8.8.8.8 -n 2 -l 1472) Capturing on &apos;Ethernet 2&apos; 1 0.000000 10.1.1.1 → 8.8.8.8 ICMP 1514 Echo (ping) request id=0x0001, seq=8/2048, ttl=128 2 0.015698 8.8.8.8 → 10.1.1.1 ICMP 106 Echo (ping) reply id=0x0001, seq=8/2048, ttl=45 2 packets captured When we ping with just one more byte, you can see that 2 packets are sent in place of 1 ((ping 8.8.8.8 -n 2 -l 1473) Capturing on &apos;Ethernet 2&apos; 1 0.000000 10.1.1.1 → 8.8.8.8 IPv4 1514 Fragmented IP protocol (proto=ICMP 1, off=0, ID=4fab) 2 0.000016 10.1.1.1 → 8.8.8.8 ICMP 35 Echo (ping) request id=0x0001, seq=10/2560, ttl=128 2 packets captured So when we ping with 5000 bytes, 4 packets are sent. And ICMP protocol considers a datagram to be lost even when one of them fails. So the probability of the ICMP datagram loss is higher than the probability of single frame loss. But is this what is happening in the ping test result? We can calculate the probability of datagram loss using probability theory but let us defer to it later on and do a numerical simulation first using Monte Carlo simulation. Monte Carlo Simulation Monte carlo simulation is a rather fancy title for a simple simulation using random event generator, but it is quite handy and widely used. Usually Monte Carlo simulation is useful for simulating events that are truly random in nature. In a chaotic backbone network, that handles traffic stream of different kinds, we can assume the frame loss to happen approximately in a random fashion. Let us write a short program to simulate random packet loss. import random import numpy as np sampleCount = 100000 # total events in our simulation p = 0.03 # ethernet frame loss probability grpSize = 4 # packet count per datagram, 5000 bytes = 4 packets grpEventCount = int(sampleCount/grpSize) # datagram count # generate random packets with p% packet loss events = np.random.choice([0,1], size=sampleCount, p=[p,1-p]) # group discrete packets into a datagram grpEvents = events.reshape(grpEventCount,grpSize) # function to determine datagram loss def checkFailure(grpEvent): return (np.count_nonzero(grpEvent) &amp;lt; grpSize) # Return 1 if the success count is less than 3 # count the result failCount = 0 for grpEvent in grpEvents: failCount += checkFailure(grpEvent) print(&quot;The probability of a group failure is {:.2f}%&quot;.format(failCount/len(grpEvents)*100)) The probability of a group failure is 11.78% There you see! Even a 3% ethernet frame loss translates to 12% packet loss for jumbo ping test. This is same as what we observed. Now this is just a simulation with random input. But does the math agree? Using Probability Theory If p is the probability of a single frame loss, (1-p) is the probability of a successful transfer. And a datagram is successful only if all of its frames are successful. So an ICMP datagram which is 4 frame long, will have (1-p)**4 probability of succesful delivery. To calculate the failure rate, just take its inverse. 1- (1-p)**4 0.11470719000000007 As expected the simulation is slightly off from the calculated probability. But it will get closer to the real figure when we increase the simulation count. Conclusion The exactness of our calculation hinges on the assumption of random nature of packet loss. While it happened to be close to true in my case, it need not be all the time. The link may be loaded in a bursty manner and since our ping streams are evenly spaced over time, their chances of failure may not be truly random. Nevertheless, we should be wary of the difference between a datagram loss and ethernet loss while interpreting results. Consider the MTU of the network path while testing with different packet sizes. Jupyter notebook version of this post can be viewed here">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jumbo Ping Fallacy- Using Monte-Carlo Simulation to model ping loss behavior">
<meta name="twitter:description" content="Background Recently we had a cabling issue in our core infrastructure which caused around 3 to 12% packet loss across few IP streams. One of my colleagues made an interesting observation that when he tried to ping with large packet size (5000 bytes) the packet loss rose up to 40%. In his opinion, that meant some applications were experiencing up to 40% packet loss. I seldom do large packet ping tests unless I am troubleshooting MTU issues, so to me this observation was interesting. At the outset, it may look like an aggravated problem. But you know that your network path MTU doesn’t support jumbo frames end-to-end. If so why is there a difference in packet loss rate when you ping with large datagams? Once you reason that the ping test results only represent ICMP datagram loss and not ethernet frame loss, you will realize that both tests results represent the same network performane but in different metrics. Interpreting them as two separate test cases is fallacious. Let us explore why. Normal ping vs Large ping In windows a normal ping packet size is 32 bytes and in most environments, the default MTU is 1500 bytes. So a single frame is sufficient to transmit a ping packet. Things get weirder when we ping with large packets. In windows, you can specify the ping packet size using -l option. Note that this size doesn’t include the packet header (20 bytes for IP header + 8 bytes for ICMP header). Which means with a 1500 MTU size, we can send only up to 1472 bytes in a single frame. Any length above this must be fragmented. We can test this easily. Below is the result when pinging with 1472 as the ping size (ping 8.8.8.8 -n 2 -l 1472) Capturing on &apos;Ethernet 2&apos; 1 0.000000 10.1.1.1 → 8.8.8.8 ICMP 1514 Echo (ping) request id=0x0001, seq=8/2048, ttl=128 2 0.015698 8.8.8.8 → 10.1.1.1 ICMP 106 Echo (ping) reply id=0x0001, seq=8/2048, ttl=45 2 packets captured When we ping with just one more byte, you can see that 2 packets are sent in place of 1 ((ping 8.8.8.8 -n 2 -l 1473) Capturing on &apos;Ethernet 2&apos; 1 0.000000 10.1.1.1 → 8.8.8.8 IPv4 1514 Fragmented IP protocol (proto=ICMP 1, off=0, ID=4fab) 2 0.000016 10.1.1.1 → 8.8.8.8 ICMP 35 Echo (ping) request id=0x0001, seq=10/2560, ttl=128 2 packets captured So when we ping with 5000 bytes, 4 packets are sent. And ICMP protocol considers a datagram to be lost even when one of them fails. So the probability of the ICMP datagram loss is higher than the probability of single frame loss. But is this what is happening in the ping test result? We can calculate the probability of datagram loss using probability theory but let us defer to it later on and do a numerical simulation first using Monte Carlo simulation. Monte Carlo Simulation Monte carlo simulation is a rather fancy title for a simple simulation using random event generator, but it is quite handy and widely used. Usually Monte Carlo simulation is useful for simulating events that are truly random in nature. In a chaotic backbone network, that handles traffic stream of different kinds, we can assume the frame loss to happen approximately in a random fashion. Let us write a short program to simulate random packet loss. import random import numpy as np sampleCount = 100000 # total events in our simulation p = 0.03 # ethernet frame loss probability grpSize = 4 # packet count per datagram, 5000 bytes = 4 packets grpEventCount = int(sampleCount/grpSize) # datagram count # generate random packets with p% packet loss events = np.random.choice([0,1], size=sampleCount, p=[p,1-p]) # group discrete packets into a datagram grpEvents = events.reshape(grpEventCount,grpSize) # function to determine datagram loss def checkFailure(grpEvent): return (np.count_nonzero(grpEvent) &amp;lt; grpSize) # Return 1 if the success count is less than 3 # count the result failCount = 0 for grpEvent in grpEvents: failCount += checkFailure(grpEvent) print(&quot;The probability of a group failure is {:.2f}%&quot;.format(failCount/len(grpEvents)*100)) The probability of a group failure is 11.78% There you see! Even a 3% ethernet frame loss translates to 12% packet loss for jumbo ping test. This is same as what we observed. Now this is just a simulation with random input. But does the math agree? Using Probability Theory If p is the probability of a single frame loss, (1-p) is the probability of a successful transfer. And a datagram is successful only if all of its frames are successful. So an ICMP datagram which is 4 frame long, will have (1-p)**4 probability of succesful delivery. To calculate the failure rate, just take its inverse. 1- (1-p)**4 0.11470719000000007 As expected the simulation is slightly off from the calculated probability. But it will get closer to the real figure when we increase the simulation count. Conclusion The exactness of our calculation hinges on the assumption of random nature of packet loss. While it happened to be close to true in my case, it need not be all the time. The link may be loaded in a bursty manner and since our ping streams are evenly spaced over time, their chances of failure may not be truly random. Nevertheless, we should be wary of the difference between a datagram loss and ethernet loss while interpreting results. Consider the MTU of the network path while testing with different packet sizes. Jupyter notebook version of this post can be viewed here">


<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://localhost:4000/"/>





  <title>Jumbo Ping Fallacy- Using Monte-Carlo Simulation to model ping loss behavior</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-108447382-1', 'auto');
  ga('send', 'pageview');
</script>













</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> <div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Ephemeral Electrons</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">A thought, a code, an ephemeral dance of electrons</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            Sitemap
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

<div id="posts" class="posts-expand">
  
  

  

  
  
  

  <article class="post post-type- " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://localhost:4000/modelling/2017/11/24/jumbo-ping-fallacy-using-monte-carlo-simulation-to-model-ping-loss-behavior/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Tamizh">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/assets/images/confused-monkey.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ephemeral Electrons">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
          
          
            Jumbo Ping Fallacy- Using Monte-Carlo Simulation to model ping loss behavior
          
        </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-11-24T08:01:28+08:00">
                2017-11-24
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/category/#/Modelling" itemprop="url" rel="index">
                    <span itemprop="name">Modelling</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          
            
          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="background">Background</h2>
<p>Recently we had a cabling issue in our core infrastructure which caused around 3 to 12% packet loss across few IP streams. One of my colleagues made an interesting observation that when he tried to ping with large packet size (5000 bytes) the packet loss rose up to 40%. In his opinion, that meant some applications were experiencing up to 40% packet loss. I seldom do large packet ping tests unless I am troubleshooting MTU issues, so to me this observation was interesting.</p>

<p>At the outset, it may look like an aggravated problem. But you know that your network path MTU doesn’t support jumbo frames end-to-end. If so why is there a difference in packet loss rate when you ping with large datagams? Once you reason that the ping test results only represent ICMP datagram loss and not ethernet frame loss, you will realize that both tests results represent the same network performane but in different metrics. Interpreting them as two separate test cases is fallacious. Let us explore why.</p>

<h2 id="normal-ping-vs-large-ping">Normal ping vs Large ping</h2>
<p>In windows a normal ping packet size is 32 bytes and in most environments, the default MTU is 1500 bytes. So a single frame is sufficient to transmit a ping packet. Things get weirder when we ping with large packets. In windows, you can specify the ping packet size using -l option. Note that this size doesn’t include the packet header (20 bytes for IP header + 8 bytes for ICMP header). Which means with a 1500 MTU size, we can send only up to 1472 bytes in a single frame. Any length above this must be fragmented.</p>

<p>We can test this easily. Below is the result when pinging with 1472 as the ping size (<code class="highlighter-rouge">ping 8.8.8.8 -n 2 -l 1472</code>)</p>
<div class="highlighter-rouge"><pre class="highlight"><code>Capturing on 'Ethernet 2'
    1   0.000000     10.1.1.1 → 8.8.8.8      ICMP 1514 Echo (ping) request  id=0x0001, seq=8/2048, ttl=128
    2   0.015698      8.8.8.8 → 10.1.1.1     ICMP 106 Echo (ping) reply    id=0x0001, seq=8/2048, ttl=45
2 packets captured
</code></pre>
</div>

<p>When we ping with just one more byte, you can see that 2 packets are sent in place of 1 ((<code class="highlighter-rouge">ping 8.8.8.8 -n 2 -l 1473</code>)</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Capturing on 'Ethernet 2'
    1   0.000000     10.1.1.1 → 8.8.8.8      IPv4 1514 Fragmented IP protocol (proto=ICMP 1, off=0, ID=4fab)
    2   0.000016     10.1.1.1 → 8.8.8.8      ICMP 35 Echo (ping) request  id=0x0001, seq=10/2560, ttl=128
2 packets captured
</code></pre>
</div>

<p>So when we ping with 5000 bytes, 4 packets are sent. And ICMP protocol considers a datagram to be lost even when one of them fails. So the probability of the ICMP datagram loss is higher than the probability of single frame loss.</p>

<p>But is this what is happening in the ping test result? We can calculate the probability of datagram loss using probability theory but let us defer to it later on and do a numerical simulation first using Monte Carlo simulation.</p>

<h2 id="monte-carlo-simulation">Monte Carlo Simulation</h2>
<p><a href="https://www.wikiwand.com/en/Monte_Carlo_method">Monte carlo simulation</a> is a rather fancy title for a simple simulation using random event generator, but it is quite handy and widely used. Usually Monte Carlo simulation is useful for simulating events that are truly random in nature. In a chaotic backbone network, that handles traffic stream of different kinds, we can assume the frame loss to happen approximately in a random fashion.</p>

<p>Let us write a short program to simulate random packet loss.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">sampleCount</span> <span class="o">=</span> <span class="mi">100000</span>                               <span class="c"># total events in our simulation</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">0.03</span>                                           <span class="c"># ethernet frame loss probability</span>
<span class="n">grpSize</span> <span class="o">=</span> <span class="mi">4</span>                                        <span class="c"># packet count per datagram, 5000 bytes = 4 packets</span>
<span class="n">grpEventCount</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">sampleCount</span><span class="o">/</span><span class="n">grpSize</span><span class="p">)</span>           <span class="c"># datagram count</span>

<span class="c"># generate random packets with p% packet loss</span>
<span class="n">events</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
                          <span class="n">size</span><span class="o">=</span><span class="n">sampleCount</span><span class="p">,</span>
                          <span class="n">p</span><span class="o">=</span><span class="p">[</span><span class="n">p</span><span class="p">,</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">])</span>

<span class="c"># group discrete packets into a datagram</span>
<span class="n">grpEvents</span> <span class="o">=</span> <span class="n">events</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">grpEventCount</span><span class="p">,</span><span class="n">grpSize</span><span class="p">)</span> 

<span class="c"># function to determine datagram loss</span>
<span class="k">def</span> <span class="nf">checkFailure</span><span class="p">(</span><span class="n">grpEvent</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">grpEvent</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">grpSize</span><span class="p">)</span>    <span class="c"># Return 1 if the success count is less than 3</span>

<span class="c"># count the result</span>
<span class="n">failCount</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">grpEvent</span> <span class="ow">in</span> <span class="n">grpEvents</span><span class="p">:</span>
    <span class="n">failCount</span> <span class="o">+=</span> <span class="n">checkFailure</span><span class="p">(</span><span class="n">grpEvent</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"The probability of a group failure is {:.2f}</span><span class="si">%</span><span class="s">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">failCount</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">grpEvents</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>The probability of a group failure is 11.78%
</code></pre>
</div>

<p>There you see! Even a 3% ethernet frame loss translates to 12% packet loss for jumbo ping test. This is same as what we observed. Now this is just a simulation with random input. But does the math agree?</p>

<h2 id="using-probability-theory">Using Probability Theory</h2>
<p>If <code class="highlighter-rouge">p</code> is the probability of a single frame loss, <code class="highlighter-rouge">(1-p)</code> is the probability of a successful transfer. And a datagram is successful only if all of its frames are successful. So an ICMP datagram which is 4 frame long, will have <code class="highlighter-rouge">(1-p)**4</code> probability of succesful delivery. To calculate the failure rate, just take its inverse.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="mi">1</span><span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span><span class="o">**</span><span class="mi">4</span>
</code></pre>
</div>
<div class="highlighter-rouge"><pre class="highlight"><code>0.11470719000000007
</code></pre>
</div>

<p>As expected the simulation is slightly off from the calculated probability. But it will get closer to the real figure when we increase the simulation count.</p>

<h2 id="conclusion">Conclusion</h2>
<p>The exactness of our calculation hinges on the assumption of random nature of packet loss. While it happened to be close to true in my case, it need not be all the time. The link may be loaded in a bursty manner and since our ping streams are evenly spaced over time, their chances of failure may not be truly random.</p>

<p>Nevertheless, we should be wary of the difference between a datagram loss and ethernet loss while interpreting results. Consider the MTU of the network path while testing with different packet sizes.</p>

<h6 id="jupyter-notebook-version-of-this-post-can-be-viewed-here">Jupyter notebook version of this post can be viewed <a href="https://goo.gl/DYxpCo">here</a></h6>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            
            <a href="/tag/#/network" rel="tag"># network</a>
          
            
            <a href="/tag/#/python" rel="tag"># python</a>
          
            
            <a href="/tag/#/numpy" rel="tag"># numpy</a>
          
            
            <a href="/tag/#/probability" rel="tag"># probability</a>
          
            
            <a href="/tag/#/scripting" rel="tag"># scripting</a>
          
        </div>
      

      
      
      
      
      

      
      
        <div class="post-nav" id="post-nav-id">
          <div class="post-nav-next post-nav-item">
            
              <a href="/modelling/2017/12/09/2017-12-09-solving-an-ancient-chinese-math-puzzle-with-constraint-programming-using-googles-or-tools/" rel="next" title="Solving an ancient Chinese math puzzle with Constraint Programming using Google's OR-Tools">
                <i class="fa fa-chevron-left"></i> Solving an ancient Chinese math puzzle with Constraint Programming using Google's OR-Tools
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/scripting/2017/10/29/emulating-angryip-scanner-with-nmap-scripting-engine-a-lua-scripting-primer/" rel="prev" title="Emulating Angry IP Scanner with nmap scripting engine - A lua scripting primer">
                Emulating Angry IP Scanner with nmap scripting engine - A lua scripting primer <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      
      

      
    </footer>
  </article>

  <div class="post-spread">
    
  </div>
</div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          

  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      
        
        
        




      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/assets/images/confused-monkey.jpg"
               alt="Tamizh" />
          <p class="site-author-name" itemprop="name">Tamizh</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/">
                <span class="site-state-item-count">32</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        
        
        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              
              
              <span class="links-of-author-item">
                <a href="https://www.linkedin.com/in/thamizh/" target="_blank" title="LinkedIn">
                  
                    <i class="fa fa-fw fa-linkedin"></i>
                  
                  LinkedIn
                </a>
              </span>
            
              
              
              <span class="links-of-author-item">
                <a href="https://github.com/thamizh85" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              
              
              <span class="links-of-author-item">
                <a href="https://twitter.com/t4m1zh" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            





            
              <div class="post-toc-content">
    <ol class=nav>
      <li class="nav-item nav-level-2"> <a class="nav-link" href="#background"> <span class="nav-number">1</span> <span class="nav-text">Background</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#normal-ping-vs-large-ping"> <span class="nav-number">2</span> <span class="nav-text">Normal ping vs Large ping</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#monte-carlo-simulation"> <span class="nav-number">3</span> <span class="nav-text">Monte Carlo Simulation</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#using-probability-theory"> <span class="nav-number">4</span> <span class="nav-text">Using Probability Theory</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> </li></ol> </li></ol> </li></ol> </li></ol> </li> <li class="nav-item nav-level-2"> <a class="nav-link" href="#conclusion"> <span class="nav-number">5</span> <span class="nav-text">Conclusion</span> </a> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <ol class="nav-child"> <li class="nav-item nav-level-6"> <a class="nav-link" href="#jupyter-notebook-version-of-this-post-can-be-viewed-here"> <span class="nav-number">5.0.0.0.1</span> <span class="nav-text">Jupyter notebook version of this post can be viewed here</a</span> </a>
    </ol>
  </div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>

        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-hand-spock-o"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Tamizh</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://jekyllrb.com">Jekyll</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/simpleyyt/jekyll-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>





















  
   
  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/jquery/index.js?v=2.1.3"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  
  
  
  
  <script type="text/javascript" src="/assets/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/assets/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/assets/js/src/motion.js?v=5.1.1"></script>



  
  

  <script type="text/javascript" src="/assets/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/assets/js/src/post-details.js?v=5.1.1"></script>


  


  <script type="text/javascript" src="/assets/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  




  

    

  





  






  

  

  
  


  

  

  

</body>
</html>

